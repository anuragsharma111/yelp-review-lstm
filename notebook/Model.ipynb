{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../data/clean.pkl\", \"rb\") as f:\n",
    "    data = torch.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output_size = cell_size = hidden_size = input_size = embedding_size\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, cell_size, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell_size = cell_size\n",
    "        self.gate = nn.Linear(input_size + hidden_size, cell_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax()\n",
    "        self.output_size = output_size\n",
    "        if self.output_size:\n",
    "            self.output = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden, cell):\n",
    "        combined = torch.cat((input, hidden), 1)\n",
    "        f_gate = self.gate(combined)\n",
    "        i_gate = self.gate(combined)\n",
    "        o_gate = self.gate(combined)\n",
    "        f_gate = self.sigmoid(f_gate)\n",
    "        i_gate = self.sigmoid(i_gate)\n",
    "        o_gate = self.sigmoid(o_gate)\n",
    "        cell_helper = self.gate(combined)\n",
    "        cell_helper = self.tanh(cell_helper)\n",
    "        cell = torch.add(torch.mul(cell, f_gate), other=torch.mul(cell_helper, i_gate))\n",
    "        hidden = torch.mul(self.tanh(cell), o_gate)\n",
    "        if self.output_size:\n",
    "            output = self.output(hidden)\n",
    "            output = self.softmax(output)\n",
    "            return output, hidden, cell\n",
    "        else:\n",
    "            return hidden, cell\n",
    "\n",
    "    def initHidden(self):\n",
    "        return Variable(torch.zeros(1, self.hidden_size))\n",
    "\n",
    "    def initCell(self):\n",
    "        return Variable(torch.zeros(1, self.cell_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def output2category(output):\n",
    "    top_n, top_i = output.data.topk(1) # Tensor out of Variable with .data\n",
    "    category_i = top_i[0][0]\n",
    "    return all_categories[category_i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(sentensor_list, category_tensor):\n",
    "    s_hidden = sentence_model.initHidden()\n",
    "    s_cell = sentence_model.initCell()\n",
    "    w_hidden = word_model.initHidden()\n",
    "    w_cell = word_model.initCell()\n",
    "    s_optimizer.zero_grad()\n",
    "    w_optimizer.zero_grad()\n",
    "    \n",
    "    for i in range(len(sentensor_list)):\n",
    "        sentensor = Variable(sentensor_list[i])\n",
    "        for j in range(sentensor.size()[0]):\n",
    "            word_tensor = sentensor[j].view(1, sentensor.size()[1])\n",
    "            w_hidden, w_cell = word_model(word_tensor, w_hidden, w_cell)\n",
    "        output, s_hidden, s_cell = sentence_model(w_cell, s_hidden, s_cell)\n",
    "        \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "    \n",
    "    w_optimizer.step()\n",
    "    s_optimizer.step()\n",
    "    return output, loss.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_choice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "def random_gen():\n",
    "    sample = random_choice(data)\n",
    "    sentensor_list = sample[0]\n",
    "    category = sample[1]\n",
    "    category_tensor = Variable(torch.LongTensor([all_categories.index(category)]))\n",
    "    return sentensor_list, category_tensor, category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_categories = [1, 2, 3, 4, 5]\n",
    "n_categories = len(all_categories)\n",
    "embedding_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "s_n_hidden = embedding_size\n",
    "s_n_cell = embedding_size\n",
    "w_n_hidden = embedding_size\n",
    "w_n_cell = embedding_size\n",
    "\n",
    "s_learning_rate = 0.005\n",
    "s_gamma = 0.1\n",
    "w_learning_rate = 0.005\n",
    "w_gamma = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "sentence_model = LSTM(w_n_cell, s_n_hidden, s_n_cell, n_categories)\n",
    "word_model = LSTM(embedding_size, w_n_hidden, w_n_cell, output_size=False)\n",
    "s_optimizer = torch.optim.Adam(sentence_lstm.parameters(), lr=s_learning_rate, weight_decay=s_gamma)\n",
    "w_optimizer = torch.optim.Adam(word_lstm.parameters(), lr=w_learning_rate, weight_decay=w_gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # test\n",
    "# l, ct, c = random_gen()\n",
    "# s_hidden = sentence_model.initHidden()\n",
    "# s_cell = sentence_model.initCell()\n",
    "# w_hidden = word_model.initHidden()\n",
    "# w_cell = word_model.initCell()\n",
    "\n",
    "# o, lo = train(l, ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 5% (0m 7s) 1.5958 / 4 ✗ (5)\n",
      "100 10% (0m 15s) 1.5064 / 4 ✓\n",
      "150 15% (0m 21s) 1.8005 / 4 ✗ (3)\n",
      "200 20% (0m 29s) 1.5958 / 4 ✗ (5)\n",
      "250 25% (0m 35s) 1.5064 / 4 ✓\n",
      "300 30% (0m 42s) 1.5064 / 4 ✓\n",
      "350 35% (0m 49s) 1.6060 / 4 ✗ (5)\n",
      "400 40% (0m 56s) 1.5813 / 4 ✗ (5)\n",
      "450 45% (1m 2s) 1.5064 / 4 ✓\n",
      "500 50% (1m 8s) 1.5813 / 4 ✗ (5)\n",
      "550 55% (1m 15s) 1.5064 / 4 ✓\n",
      "600 60% (1m 22s) 1.5064 / 4 ✓\n",
      "650 65% (1m 28s) 1.5064 / 4 ✓\n",
      "700 70% (1m 35s) 1.5064 / 4 ✓\n",
      "750 75% (1m 42s) 1.8005 / 4 ✗ (3)\n",
      "800 80% (1m 48s) 1.5813 / 4 ✗ (5)\n",
      "850 85% (1m 54s) 1.6060 / 4 ✗ (5)\n",
      "900 90% (2m 1s) 1.5958 / 4 ✗ (5)\n",
      "950 95% (2m 8s) 1.8005 / 4 ✗ (3)\n",
      "1000 100% (2m 15s) 1.6060 / 4 ✗ (5)\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 1000\n",
    "print_every = 50\n",
    "plot_every = 10\n",
    "\n",
    "# Keep track of losses for plotting\n",
    "current_loss = 0\n",
    "all_losses = []\n",
    "\n",
    "start = time.time()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    sentensor_list, category_tensor, category = random_gen()\n",
    "    output, loss = train(sentensor_list, category_tensor)\n",
    "    current_loss += loss\n",
    "     # Print epoch number, loss, name and guess\n",
    "    if epoch % print_every == 0:\n",
    "        guess = output2category(output)\n",
    "        correct = '✓' if guess == category else '✗ (%s)' % category\n",
    "        print('%d %d%% (%s) %.4f / %s %s' % (epoch, epoch / n_epochs * 100, timeSince(start), loss, guess, correct))\n",
    "\n",
    "    # Add current loss avg to list of losses\n",
    "    if epoch % plot_every == 0:\n",
    "        all_losses.append(current_loss / plot_every)\n",
    "        current_loss = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
